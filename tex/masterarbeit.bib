@misc{vaswani2017attention,
    title = {Attention Is All You Need},
    author = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
    year = {2017},
    eprint = {1706.03762},
    archivePrefix = {arXiv},
    primaryClass = {cs.CL}
}

@misc{kiritani2020recurrent,
    title = {Recurrent Attention Model with Log-Polar Mapping is Robust against Adversarial Attacks},
    author = {Taro Kiritani and Koji Ono},
    year = {2020},
    eprint = {2002.05388},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV}
}

@misc{mnih2014recurrent,
    title = {Recurrent Models of Visual Attention},
    author = {Volodymyr Mnih and Nicolas Heess and Alex Graves and Koray Kavukcuoglu},
    year = {2014},
    eprint = {1406.6247},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG}
}

@misc{bahdanau2016neural,
    title = {Neural Machine Translation by Jointly Learning to Align and Translate},
    author = {Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
    year = {2016},
    eprint = {1409.0473},
    archivePrefix = {arXiv},
    primaryClass = {cs.CL}
}

@misc{luong2015effective,
    title = {Effective Approaches to Attention-based Neural Machine Translation},
    author = {Minh-Thang Luong and Hieu Pham and Christopher D. Manning},
    year = {2015},
    eprint = {1508.04025},
    archivePrefix = {arXiv},
    primaryClass = {cs.CL}
}

@misc{graves2014neural,
    title = {Neural Turing Machines},
    author = {Alex Graves and Greg Wayne and Ivo Danihelka},
    year = {2014},
    eprint = {1410.5401},
    archivePrefix = {arXiv},
    primaryClass = {cs.NE}
}

@misc{touvron2021training,
    title = {Training data-efficient image transformers \& distillation through attention},
    author = {Hugo Touvron and Matthieu Cord and Matthijs Douze and Francisco Massa and Alexandre Sablayrolles and Hervé Jégou},
    year = {2021},
    eprint = {2012.12877},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV}
}

@misc{dosovitskiy2021image,
    title = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
    author = {Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
    year = {2021},
    eprint = {2010.11929},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV}
}

@misc{parmar2018image,
    title = {Image Transformer},
    author = {Niki Parmar and Ashish Vaswani and Jakob Uszkoreit and Łukasz Kaiser and Noam Shazeer and Alexander Ku and Dustin Tran},
    year = {2018},
    eprint = {1802.05751},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV}
}

@misc{wang2021images,
    title = {Not All Images are Worth 16x16 Words: Dynamic Vision Transformers with Adaptive Sequence Length},
    author = {Yulin Wang and Rui Huang and Shiji Song and Zeyi Huang and Gao Huang},
    year = {2021},
    eprint = {2105.15075},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV}
}

@misc{ramesh2021zeroshot,
    title = {Zero-Shot Text-to-Image Generation},
    author = {Aditya Ramesh and Mikhail Pavlov and Gabriel Goh and Scott Gray and Chelsea Voss and Alec Radford and Mark Chen and Ilya Sutskever},
    year = {2021},
    eprint = {2102.12092},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV}
}

@misc{carion2020endtoend,
    title = {End-to-End Object Detection with Transformers},
    author = {Nicolas Carion and Francisco Massa and Gabriel Synnaeve and Nicolas Usunier and Alexander Kirillov and Sergey Zagoruyko},
    year = {2020},
    eprint = {2005.12872},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV}
}

@misc{wang2018nonlocal,
    title = {Non-local Neural Networks},
    author = {Xiaolong Wang and Ross Girshick and Abhinav Gupta and Kaiming He},
    year = {2018},
    eprint = {1711.07971},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV}
}

@misc{chefer2021transformer,
    title = {Transformer Interpretability Beyond Attention Visualization},
    author = {Hila Chefer and Shir Gur and Lior Wolf},
    year = {2021},
    eprint = {2012.09838},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV}
}

@misc{kitaev2020reformer,
    title = {Reformer: The Efficient Transformer},
    author = {Nikita Kitaev and Lukasz Kaiser and Anselm Levskaya},
    year = {2020},
    eprint = {2001.04451},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG}
}

@inproceedings{Radford2018ImprovingLU,
    title = {Improving Language Understanding by Generative Pre-Training},
    author = {Alec Radford and Karthik Narasimhan},
    year = {2018}
}

@article{radford2019language,
    title = {Language Models are Unsupervised Multitask Learners},
    author = {Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
    year = {2019}
}

@article{brown2020language,
    title = {Language Models are Few-Shot Learners},
    author = {Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
    year = {2020},
    eprint = {2005.14165},
    archivePrefix = {arXiv},
    primaryClass = {cs.CL}
}

@misc{devlin2019bert,
    title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
    author = {Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
    year = {2019},
    eprint = {1810.04805},
    archivePrefix = {arXiv},
    primaryClass = {cs.CL}
}

@misc{yu2021glanceandgaze,
    title = {Glance-and-Gaze Vision Transformer},
    author = {Qihang Yu and Yingda Xia and Yutong Bai and Yongyi Lu and Alan Yuille and Wei Shen},
    year = {2021},
    eprint = {2106.02277},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV}
}

@misc{kim2014convolutional,
    title = {Convolutional Neural Networks for Sentence Classification},
    author = {Yoon Kim},
    year = {2014},
    eprint = {1408.5882},
    archivePrefix = {arXiv},
    primaryClass = {cs.CL}
}

@article{yin2019cnnandrnn,
    author = {Yin, Qiwei and Zhang, Ruixun and Shao, XiuLi},
    year = {2019},
    month = {01},
    pages = {02001},
    title = {CNN and RNN mixed model for image classification},
    volume = {277},
    journal = {MATEC Web of Conferences},
    doi = {10.1051/matecconf/201927702001}
}

@ARTICLE{itti1998amodelof,
    author = {Itti, L. and Koch, C. and Niebur, E.},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    title = {A model of saliency-based visual attention for rapid scene analysis},
    year = {1998},
    volume = {20},
    number = {11},
    pages = {1254-1259},
    doi = {10.1109/34.730558}
}

@misc{ranzato2014learning,
    title = {On Learning Where To Look},
    author = {Marc'Aurelio Ranzato},
    year = {2014},
    eprint = {1405.5488},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV}
}

@misc{abnar2020quantifying,
    title = {Quantifying Attention Flow in Transformers},
    author = {Samira Abnar and Willem Zuidema},
    year = {2020},
    eprint = {2005.00928},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG}
}

@article{goldberg1988anew,
    author = {Goldberg, Andrew V. and Tarjan, Robert E.},
    title = {A New Approach to the Maximum-Flow Problem},
    year = {1988},
    issue_date = {Oct. 1988},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {35},
    number = {4},
    issn = {0004-5411},
    url = {https://doi.org/10.1145/48014.61051},
    doi = {10.1145/48014.61051},
    journal = {J. ACM},
    month = oct,
    pages = {921–940},
    numpages = {20}
}

@misc{kirillov2019panoptic,
    title = {Panoptic Segmentation},
    author = {Alexander Kirillov and Kaiming He and Ross Girshick and Carsten Rother and Piotr Dollár},
    year = {2019},
    eprint = {1801.00868},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV}
}


@InProceedings{chen2020generative,
    title = {Generative Pretraining From Pixels},
    author = {Chen, Mark and Radford, Alec and Child, Rewon and Wu, Jeffrey and Jun, Heewoo and Luan, David and Sutskever, Ilya},
    booktitle = {Proceedings of the 37th International Conference on Machine Learning},
    pages = {1691--1703},
    year = {2020},
    editor = {III, Hal Daumé and Singh, Aarti},
    volume = {119},
    series = {Proceedings of Machine Learning Research},
    month = {13--18 Jul},
    publisher = {PMLR},
    pdf = {http://proceedings.mlr.press/v119/chen20s/chen20s.pdf},
    url = {https://proceedings.mlr.press/v119/chen20s.html},
}

@InProceedings{he2021image,
    author = {He, Sen and Liao, Wentong and Tavakoli, Hamed R. and Yang, Michael and Rosenhahn, Bodo and Pugeault, Nicolas},
    editor = {Ishikawa, Hiroshi and Liu, Cheng-Lin and Pajdla, Tomas and Shi, Jianbo},
    title = {Image Captioning Through Image Transformer},
    booktitle = {Computer Vision -- ACCV 2020},
    year = {2021},
    publisher = {Springer International Publishing},
    address = {Cham},
    pages = {153--169},
    isbn = {978-3-030-69538-5},
}

@misc{zhou2021convnets,
    title = {ConvNets vs. Transformers: Whose Visual Representations are More Transferable?},
    author = {Hong-Yu Zhou and Chixiang Lu and Sibei Yang and Yizhou Yu},
    year = {2021},
    eprint = {2108.05305},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV}
}

@misc{guo2021cmt,
    title = {CMT: Convolutional Neural Networks Meet Vision Transformers},
    author = {Jianyuan Guo and Kai Han and Han Wu and Chang Xu and Yehui Tang and Chunjing Xu and Yunhe Wang},
    year = {2021},
    eprint = {2107.06263},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV}
}

@unknown{matsoukas2021isit,
    author = {Matsoukas, Christos and Haslum, Johan and Söderberg, Magnus and Smith, Kevin},
    year = {2021},
    month = {08},
    title = {Is it Time to Replace CNNs with Transformers for Medical Images?}
}

@InProceedings{wu2021visual,
    author = {Wu, Bichen and Xu, Chenfeng and Dai, Xiaoliang and Wan, Alvin and Zhang, Peizhao and Yan, Zhicheng and Tomizuka, Masayoshi and Gonzalez, Joseph E. and Keutzer, Kurt and Vajda, Peter},
    title = {Visual Transformers: Where Do Transformers Really Belong in Vision Models?},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month = {October},
    year = {2021},
    pages = {599-609}
}

@misc{wu2020visualV3,
    title = {Visual Transformers: Token-based Image Representation and Processing for Computer Vision},
    author = {Bichen Wu and Chenfeng Xu and Xiaoliang Dai and Alvin Wan and Peizhao Zhang and Zhicheng Yan and Masayoshi Tomizuka and Joseph Gonzalez and Kurt Keutzer and Peter Vajda},
    year = {2020},
    eprint = {2006.03677},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV}
}

@unknown{tuli2021are,
    author = {Tuli, Shikhar and Dasgupta, Ishita and Grant, Erin and Griffiths, Thomas},
    year = {2021},
    month = {05},
    title = {Are Convolutional Neural Networks or Transformers more like human vision?}
}

@misc{xiao2021early,
    title = {Early Convolutions Help Transformers See Better},
    author = {Tete Xiao and Mannat Singh and Eric Mintun and Trevor Darrell and Piotr Dollár and Ross Girshick},
    year = {2021},
    eprint = {2106.14881},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV}
}

@misc{simonyan2015deep,
    title = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
    author = {Karen Simonyan and Andrew Zisserman},
    year = {2015},
    eprint = {1409.1556},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV}
}

@misc{howard2017mobilenets,
    title = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications},
    author = {Andrew G. Howard and Menglong Zhu and Bo Chen and Dmitry Kalenichenko and Weijun Wang and Tobias Weyand and Marco Andreetto and Hartwig Adam},
    year = {2017},
    eprint = {1704.04861},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV}
}

@misc{sandler2019mobilenetv2,
    title = {MobileNetV2: Inverted Residuals and Linear Bottlenecks},
    author = {Mark Sandler and Andrew Howard and Menglong Zhu and Andrey Zhmoginov and Liang-Chieh Chen},
    year = {2019},
    eprint = {1801.04381},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV}
}

@misc{he2015deep,
    title = {Deep Residual Learning for Image Recognition},
    author = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
    year = {2015},
    eprint = {1512.03385},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV}
}

@misc{chen2021evaluating,
    title = {Evaluating Large Language Models Trained on Code},
    author = {Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde de Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and Dave Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William Hebgen Guss and Alex Nichol and Alex Paino and Nikolas Tezak and Jie Tang and Igor Babuschkin and Suchir Balaji and Shantanu Jain and William Saunders and Christopher Hesse and Andrew N. Carr and Jan Leike and Josh Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
    year = {2021},
    eprint = {2107.03374},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG}
}


@misc{dumoulin2018guide,
    title = {A guide to convolution arithmetic for deep learning},
    author = {Vincent Dumoulin and Francesco Visin},
    year = {2018},
    eprint = {1603.07285},
    archivePrefix = {arXiv},
    primaryClass = {stat.ML}
}

@INPROCEEDINGS{dumitru2014scalable,
    author = {Erhan, Dumitru and Szegedy, Christian and Toshev, Alexander and Anguelov, Dragomir},
    booktitle = {2014 IEEE Conference on Computer Vision and Pattern Recognition},
    title = {Scalable Object Detection Using Deep Neural Networks},
    year = {2014},
    pages = {2155-2162},
    doi = {10.1109/CVPR.2014.276}
}

@misc{lin2018focal,
    title = {Focal Loss for Dense Object Detection},
    author = {Tsung-Yi Lin and Priya Goyal and Ross Girshick and Kaiming He and Piotr Dollár},
    year = {2018},
    eprint = {1708.02002},
    archivePrefix = {arXiv},
    primaryClass = {cs.CV}
}

@article{wei2016single,
    title = {SSD: Single Shot MultiBox Detector},
    ISSN = {1611-3349},
    url = {http://dx.doi.org/10.1007/978-3-319-46448-0_2},
    DOI = {10.1007/978-3-319-46448-0_2},
    journal = {Lecture Notes in Computer Science},
    publisher = {Springer International Publishing},
    author = {Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C.},
    year = {2016},
    pages = {21–37}
}

@misc{wang2019glue,
    title = {GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},
    author = {Alex Wang and Amanpreet Singh and Julian Michael and Felix Hill and Omer Levy and Samuel R. Bowman},
    year = {2019},
    eprint = {1804.07461},
    archivePrefix = {arXiv},
    primaryClass = {cs.CL}
}
